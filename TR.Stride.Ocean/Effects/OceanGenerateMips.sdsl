namespace TR.Stride.Ocean
{
    shader OceanGenerateMips : ComputeShaderBase
    {
        stage SamplerState BilinearClamp
        {
            Filter = MIN_MAG_MIP_LINEAR;
            AddressU = Clamp;
            AddressV = Clamp;
        };

        stage Texture2D<float4> SrcMip;
        stage RWTexture2D<float4> OutMip1;
        stage RWTexture2D<float4> OutMip2;
        stage RWTexture2D<float4> OutMip3;
        stage RWTexture2D<float4> OutMip4;

        stage uint SrcMipLevel;
        stage uint NumMipLevels;
        stage float2 TexelSize;

        // The reason for separating channels is to reduce bank conflicts in the
        // local data memory controller.  A large stride will cause more threads
        // to collide on the same memory bank.
        groupshared float gs_R[64];
        groupshared float gs_G[64];
        groupshared float gs_B[64];
        groupshared float gs_A[64];

        void StoreColor( uint Index, float4 Color )
        {
            gs_R[Index] = Color.r;
            gs_G[Index] = Color.g;
            gs_B[Index] = Color.b;
            gs_A[Index] = Color.a;
        }

        float4 LoadColor( uint Index )
        {
            return float4( gs_R[Index], gs_G[Index], gs_B[Index], gs_A[Index]);
        }

        override void Compute()
        {
            float2 UV = TexelSize * (streams.DispatchThreadId.xy + 0.5);
            float4 Src1 = SrcMip.SampleLevel(BilinearClamp, UV, SrcMipLevel);

            OutMip1[streams.DispatchThreadId.xy] = Src1;

            // A scalar (constant) branch can exit all threads coherently.
            if (NumMipLevels == 1)
                return;

            // Without lane swizzle operations, the only way to share data with other
            // threads is through LDS.
            StoreColor(streams.GroupIndex, Src1);

            // This guarantees all LDS writes are complete and that all threads have
            // executed all instructions so far (and therefore have issued their LDS
            // write instructions.)
            GroupMemoryBarrierWithGroupSync();

            // With low three bits for X and high three bits for Y, this bit mask
            // (binary: 001001) checks that X and Y are even.
            if ((streams.GroupIndex & 0x9) == 0)
            {
                float4 Src2 = LoadColor(streams.GroupIndex + 0x01);
                float4 Src3 = LoadColor(streams.GroupIndex + 0x08);
                float4 Src4 = LoadColor(streams.GroupIndex + 0x09);
                Src1 = 0.25 * (Src1 + Src2 + Src3 + Src4);

                OutMip2[streams.DispatchThreadId.xy / 2] = Src1;
                StoreColor(streams.GroupIndex, Src1);
            }

            if (NumMipLevels == 2)
                return;

            GroupMemoryBarrierWithGroupSync();

            // This bit mask (binary: 011011) checks that X and Y are multiples of four.
            if ((streams.GroupIndex & 0x1B) == 0)
            {
                float4 Src2 = LoadColor(streams.GroupIndex + 0x02);
                float4 Src3 = LoadColor(streams.GroupIndex + 0x10);
                float4 Src4 = LoadColor(streams.GroupIndex + 0x12);
                Src1 = 0.25 * (Src1 + Src2 + Src3 + Src4);

                OutMip3[streams.DispatchThreadId.xy / 4] = Src1;
                StoreColor(streams.GroupIndex, Src1);
            }

            if (NumMipLevels == 3)
                return;

            GroupMemoryBarrierWithGroupSync();

            // This bit mask would be 111111 (X & Y multiples of 8), but only one
            // thread fits that criteria.
            if (streams.GroupIndex == 0)
            {
                float4 Src2 = LoadColor(streams.GroupIndex + 0x04);
                float4 Src3 = LoadColor(streams.GroupIndex + 0x20);
                float4 Src4 = LoadColor(streams.GroupIndex + 0x24);
                Src1 = 0.25 * (Src1 + Src2 + Src3 + Src4);

                OutMip4[streams.DispatchThreadId.xy / 8] = Src1;
            }
        }
    };
}